package tcd;

import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.core.KeywordAnalyzer;
import org.apache.lucene.analysis.core.SimpleAnalyzer;
import org.apache.lucene.analysis.core.StopAnalyzer;
import org.apache.lucene.analysis.core.WhitespaceAnalyzer;
import org.apache.lucene.analysis.en.EnglishAnalyzer;
import org.apache.lucene.analysis.standard.StandardAnalyzer;
import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.document.StringField;
import org.apache.lucene.document.TextField;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.IndexWriterConfig;
import org.apache.lucene.search.similarities.BM25Similarity;
import org.apache.lucene.search.similarities.ClassicSimilarity;
import org.apache.lucene.search.similarities.LMDirichletSimilarity;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;

import java.io.File;
import java.io.IOException;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.List;
import java.util.Map;

class Indexer {

   public void createCranIndex(Path indexFile, List<Map<String, String>> cranList, String analyzerString, String similarity) {

       try {

           // Create analyzer
           Analyzer analyzer = null;

           // the most commonly used analyzer:
           // Note that the StandardAnalyzer can recognize URLs and emails.
           //Also, it removes stop words and lowercases the generated tokens.
           if (analyzerString.equals("Standard")) analyzer = new StandardAnalyzer(EnglishAnalyzer.getDefaultStopSet());

           //The KeywordAnalyzer tokenizes input into a single token ,useful for fields like ids and zipcodes.
           else if (analyzerString.equals("Keyword")) analyzer = new KeywordAnalyzer();
           //The WhitespaceAnalyzer uses only a WhitespaceTokenizer which splits text by whitespace characters:
           else if (analyzerString.equals("WhiteSpace")) analyzer = new WhitespaceAnalyzer();
           //SimpleAnalyzer consists of LetterTokenizer and a LowerCaseFilter:
           // SimpleAnalyzer didn't remove stop words. It also doesn't recognize URLs.
           else if (analyzerString.equals("Simple")) analyzer = new SimpleAnalyzer();
           //In this example, the LetterTokenizer splits text by non-letter characters, while the StopFilter removes stop words from the token list.
               //However, unlike the StandardAnalyzer, StopAnalyzer isn't able to recognize URLs.
           else if (analyzerString.equals("Stop")) analyzer = new StopAnalyzer();
           //EnglishAnalyzer which consists of StandardTokenizer, StandardFilter, EnglishPossessiveFilter, LowerCaseFilter, StopFilter, and PorterStemFilter.
           else {

               analyzer = new EnglishAnalyzer();
               analyzerString = "English";
           }

           // Store index on disk
           Directory directory = FSDirectory.open(indexFile);

           // Create index writer
           IndexWriterConfig config = new IndexWriterConfig(analyzer);
           config.setOpenMode(IndexWriterConfig.OpenMode.CREATE_OR_APPEND);
           if (similarity.equals("TFIDF")) config.setSimilarity(new ClassicSimilarity());
           else if (similarity.equals("LMDirichlet")) config.setSimilarity(new LMDirichletSimilarity());
           else {

               config.setSimilarity(new BM25Similarity());
               similarity = "BM25";
           }

           System.out.println("Creating index using " + analyzerString + " analyzer and " + similarity + " similarity.");

           IndexWriter iwriter = new IndexWriter(directory, config);

           // Add documents to index
           for (int i = 0; i < cranList.size(); i++)
               addCranDocument(iwriter, cranList.get(i));

           iwriter.close();
           directory.close();
       }
       catch (IOException e) {

           e.printStackTrace();
           System.exit(1);
       }
   }

   private void addCranDocument(IndexWriter iwriter, Map<String, String> cranDict) throws IOException {

       Document document = new Document();
       document.add(new StringField("ID", cranDict.get("ID"), Field.Store.YES));
       document.add(new TextField("Title", cranDict.get("Title"), Field.Store.YES));
       document.add(new TextField("Locations", cranDict.get("Locations"), Field.Store.YES));
       document.add(new TextField("Authors", cranDict.get("Authors"), Field.Store.YES));
       document.add(new TextField("Abstract", cranDict.get("Abstract"), Field.Store.YES));
       iwriter.addDocument(document);
   }

   public static void main(String[] args) {

       String analyzer = "English";
       String similarity = "BM25";
       String hpp = "1000";
       String dataDir="data/cran";

       System.out.println("Parsing CRAN data...");
       FileIO fileIO = new FileIO();
       List<Map<String, String>> cranList = fileIO.parseCran(dataDir);
       System.out.println("Parsing done!\n");

       System.out.println("Deleting previous index files, if they exist...");
       fileIO.deleteDir(new File("index"));
       System.out.println("Done!\n");

       System.out.println("Indexing data...");
       Indexer indexer = new Indexer();
       indexer.createCranIndex(Paths.get("index/cran.index"), cranList, analyzer, similarity);
       System.out.println("Indexing done, and saved on "+Paths.get("index/cran.index")+" !");
   }


}
